{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8173997",
   "metadata": {},
   "source": [
    "**Purpose:** Compute similarities between the flavin time series of different same-length sections of the same experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee31fa",
   "metadata": {},
   "source": [
    "**Aims:**\n",
    "- Import flavin signals from multiple strains in the same experiment (and thus same nutrient conditions).\n",
    "- Process data: cut time series to duration of interest, detrend flavin signals.\n",
    "- Featurise data: use `catch22`\n",
    "- Compute the mutual information between pairs of strains, treating mutual information as any other machine learning measure.\n",
    "  - Mutual information asks the question: can you tell apart a typical time series from dataset A and a typical time series from dataset B?  0 means 'no', 1 means 'yes', intermediate values can be used as similarity measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf8ecd",
   "metadata": {},
   "source": [
    "**Paradigms:**\n",
    "- Use `aliby`-style data structures and `postprocessor` processes for featurisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6463ad",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff871db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# PARAMETERS\n",
    "filename_prefix = './data/arin/Omero19972_'\n",
    "#filename_prefix = './data/arin/Omero20071_'\n",
    "#filename_prefix = './data/arin/Omero20212_'\n",
    "#\n",
    "\n",
    "# Import flavin signals\n",
    "signal = pd.read_csv(filename_prefix+'flavin.csv')\n",
    "signal.replace(0, np.nan, inplace=True) # because the CSV is constructed like that :/\n",
    "\n",
    "# Import look-up table for strains (would prefer to directly CSV -> dict)\n",
    "strainlookup_df = pd.read_csv(filename_prefix+'strains.csv')\n",
    "strainlookup_dict = dict(zip(strainlookup_df.position, strainlookup_df.strain))\n",
    "\n",
    "# Positions -> Strain (more informative)\n",
    "signal = signal.replace({'position': strainlookup_dict})\n",
    "signal.rename(columns = {\"position\": \"strain\"}, inplace = True)\n",
    "signal = signal.drop(['distfromcentre'], axis = 1)\n",
    "\n",
    "# Convert to multi-index dataframe\n",
    "signal_temp = signal.iloc[:,2:]\n",
    "multiindex = pd.MultiIndex.from_frame(signal[['strain', 'cellID']])\n",
    "signal = pd.DataFrame(signal_temp.to_numpy(),\n",
    "                      index = multiindex)\n",
    "\n",
    "signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc9c41",
   "metadata": {},
   "source": [
    "# Choose a list of cells as working data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa0f24",
   "metadata": {},
   "source": [
    "## Strains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f88255d",
   "metadata": {},
   "source": [
    "List strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3596588",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.index.get_level_values(0).unique().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe359a",
   "metadata": {},
   "source": [
    "Define `signal_wd` as working data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62282af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal_wd = signal.loc[['htb2_mCherry_CRISPR', 'CEN_PK_Mat_A_Koetter', 'rim11_Del', 'swe1_Del', 'tsa1_Del_tsa2_Del']]\n",
    "signal_wd = signal.loc[['htb2_mCherry_CRISPR']]\n",
    "\n",
    "signal_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadefa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_wd = signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95145129",
   "metadata": {},
   "source": [
    "## Oscillatory/Non-oscillatory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5848c",
   "metadata": {},
   "source": [
    "Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55515bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_targets = 'categories_19979_detrend.csv'\n",
    "\n",
    "labels_df = pd.read_csv(filename_targets, header = None, index_col = 0)\n",
    "labels_df.index.names = ['cellID']\n",
    "labels_df.columns = ['osc_category']\n",
    "\n",
    "#labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f1f641",
   "metadata": {},
   "source": [
    "Specify whether to include:\n",
    "- non-oscillatory cells only ([0])\n",
    "- oscillatory cells only ([1])\n",
    "- all cells ([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "osc_categories_to_include = [1]\n",
    "\n",
    "indices_by_osc = labels_df[labels_df['osc_category'].isin(osc_categories_to_include)].index\n",
    "indices_intersect = signal_wd.index.get_level_values('cellID').intersection(indices_by_osc)\n",
    "signal_wd = signal_wd.loc[(slice(None), indices_intersect), :]\n",
    "\n",
    "signal_wd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e39f36",
   "metadata": {},
   "source": [
    "# Processing time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc606c",
   "metadata": {},
   "source": [
    "## Range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d1ba9",
   "metadata": {},
   "source": [
    "Define the two durations to compare (they should be same length, but I haven't built in validation here yet), remove NaNs, and re-shape the `DataFrame` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a86354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "interval1_start = 0\n",
    "interval1_end = 84\n",
    "interval2_start = 96\n",
    "interval2_end = 180\n",
    "#\n",
    "\n",
    "signal_processed1 = signal_wd.iloc[:, interval1_start:interval1_end].dropna()\n",
    "signal_processed2 = signal_wd.iloc[:, interval2_start:interval2_end].dropna()\n",
    "\n",
    "shift = interval1_end - interval1_start\n",
    "signal_processed2.columns = signal_processed1.columns\n",
    "strain2 = signal_processed2.iloc[0].name[0]\n",
    "signal_processed2.index = signal_processed2.index.set_levels(\n",
    "    signal_processed2.index.levels[0].str.replace(strain2, strain2+'_shift'), level=0\n",
    ")\n",
    "\n",
    "signal_processed = pd.concat([signal_processed1, signal_processed2])\n",
    "\n",
    "signal_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07d613",
   "metadata": {},
   "source": [
    "## Detrend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9b0d9",
   "metadata": {},
   "source": [
    "Using sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd086703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PARAMETERS\n",
    "window = 45\n",
    "#\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(signal_processed)\n",
    "plt.title('Before detrending')\n",
    "plt.show()\n",
    "\n",
    "def moving_average(input_timeseries,\n",
    "                  window = 3):\n",
    "    processed_timeseries = np.cumsum(input_timeseries, dtype=float)\n",
    "    processed_timeseries[window:] = processed_timeseries[window:] - processed_timeseries[:-window]\n",
    "    return processed_timeseries[window - 1 :] /  window\n",
    "\n",
    "signal_processed = signal_processed.div(signal_processed.mean(axis = 1), axis = 0)\n",
    "signal_movavg = signal_processed.apply(lambda x: pd.Series(moving_average(x.values, window)), axis = 1)\n",
    "signal_norm = signal_processed.iloc(axis = 1)[window//2: -window//2] / signal_movavg.iloc[:,0:signal_movavg.shape[1]-1].values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(signal_norm)\n",
    "plt.title('After detrending')\n",
    "plt.show()\n",
    "\n",
    "signal_processed = signal_norm\n",
    "\n",
    "signal_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3873f",
   "metadata": {},
   "source": [
    "# Featurisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91984c3f",
   "metadata": {},
   "source": [
    "Option 1: use `catch22`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb17d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessor.core.processes.catch22 import catch22Parameters, catch22\n",
    "\n",
    "catch22_processor = catch22(catch22Parameters.default())\n",
    "features = catch22_processor.run(signal_processed)\n",
    "\n",
    "sns.heatmap(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b7e07",
   "metadata": {},
   "source": [
    "Option 2: use time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85410a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = signal_processed\n",
    "\n",
    "sns.heatmap(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fa501",
   "metadata": {},
   "source": [
    "# Mutual information bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26cda7",
   "metadata": {},
   "source": [
    "## Use all strains in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c8366",
   "metadata": {},
   "source": [
    "Convert `DataFrame` to list of arrays as input for `estimateMI`, then compute mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ac755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessor.core.processes.mi import miParameters, mi\n",
    "\n",
    "mi_params = miParameters.default()\n",
    "mi_params.overtime = False\n",
    "mi_processor = mi(mi_params)\n",
    "results = mi_processor.run(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358e557",
   "metadata": {},
   "source": [
    "## Distance matrix based on pairwise combinations of strains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b97539",
   "metadata": {},
   "source": [
    "Compute distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1393f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from postprocessor.core.processes.mi import miParameters, mi\n",
    "\n",
    "# There is probably a smarter way to compute a distance matrix using a custom distance metric --\n",
    "# maybe there's a scipy/numpy/scikit-learn routine that simplifies code, and I can put the\n",
    "# MI-computing bit as a function.\n",
    "\n",
    "mi_params = miParameters.default()\n",
    "mi_params.overtime = False\n",
    "mi_params.n_bootstraps = 100\n",
    "mi_processor = mi(mi_params)\n",
    "\n",
    "strain_list = features.index.get_level_values('strain').unique().to_numpy()\n",
    "# Using itertools.combinations instead of two 'for' loops, one for each axis,\n",
    "# because mi.run() is computationally expensive.\n",
    "# Plus, I only need the upper triangular anyway.\n",
    "distance_matrix = np.zeros((len(strain_list), len(strain_list)))\n",
    "for strain1, strain2 in itertools.combinations_with_replacement(strain_list, 2):\n",
    "    if strain1 == strain2:\n",
    "        features_copy = features.loc[[strain1]]\n",
    "        features_copy.index = features_copy.index.set_levels(\n",
    "            features_copy.index.levels[0].str.replace(strain1, strain1+'_copy'), level=0\n",
    "        )\n",
    "        features_subset = pd.concat([features.loc[[strain1]], features_copy])\n",
    "    else:\n",
    "        features_subset = features.loc[[strain1, strain2]]\n",
    "    results = mi_processor.run(features_subset)\n",
    "    median_mi = results[0][1]\n",
    "    distance_matrix[np.argwhere(strain_list == strain1).item()][np.argwhere(strain_list == strain2).item()] = median_mi\n",
    "\n",
    "# Visualise\n",
    "sns.heatmap(\n",
    "    pd.DataFrame(\n",
    "        data = distance_matrix,\n",
    "        index = strain_list,\n",
    "        columns = strain_list,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ffec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a4e14",
   "metadata": {},
   "source": [
    "Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a39898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten upper triangular for linkage() input\n",
    "linkage_matrix = linkage(\n",
    "    distance_matrix[np.triu_indices(len(strain_list), k = 1)],\n",
    "    'average', # This parameter defines the algorithm\n",
    ")\n",
    "\n",
    "# Plot\n",
    "dendrogram(\n",
    "    linkage_matrix,\n",
    "    orientation = 'left',\n",
    "    labels = strain_list,\n",
    ")\n",
    "plt.xlabel('Distance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aliby",
   "language": "python",
   "name": "aliby"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
