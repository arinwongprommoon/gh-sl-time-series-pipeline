{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify file name and sampling period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'pipeline.vis' from '/home/arin/phd/phd-time-series-pipeline/pipeline/vis.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_prefix = './data/arin/Omero19979_'\n",
    "sampling_period = 5\n",
    "\n",
    "%matplotlib\n",
    "\n",
    "import importlib\n",
    "importlib.reload(pipeline.vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main shebang (this probably isn't the purpose of a jupyter notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './data/arin/Omero19979_mCherry.csv'\n",
      "No mCherry time series associated with this experiment: ./data/arin/Omero19979_\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "import igraph as ig\n",
    "\n",
    "import pipeline.dataexport\n",
    "import pipeline.dataimport\n",
    "import pipeline.periodogram\n",
    "import pipeline.score\n",
    "import pipeline.tsman\n",
    "import pipeline.vis\n",
    "\n",
    "import featext.tsman\n",
    "import featext.graph\n",
    "import featext.vis\n",
    "\n",
    "import catch22\n",
    "import leidenalg\n",
    "\n",
    "def add_classicalAttr(cell, oversampling_factor = 1):\n",
    "    \"\"\"Computes classical periodogram and adds PdgramAttr attributes\"\"\"\n",
    "    cell.flavin.classical.freqs, cell.flavin.classical.power = \\\n",
    "            pipeline.periodogram.classical(cell.time, cell.flavin.reading_processed,\n",
    "                                oversampling_factor = oversampling_factor)\n",
    "\n",
    "def add_bglsAttr(cell):\n",
    "    \"\"\"Computes BGLS and adds PdgramAttr attributes\"\"\"\n",
    "    cell.flavin.bgls = pipeline.PdgramAttr()\n",
    "    cell.flavin.bgls.label = 'Bayesian General Lomb-Scargle Periodogram'\n",
    "    cell.flavin.bgls.power_label = 'Probability'\n",
    "    err = np.ones(len(cell.flavin.reading_processed))*\\\n",
    "            np.sqrt(np.max(cell.flavin.reading_processed))\n",
    "    cell.flavin.bgls.freqs, cell.flavin.bgls.power = \\\n",
    "            pipeline.periodogram.bgls(cell.time, cell.flavin.reading_processed, err,\n",
    "                    plow = 30.0, phigh = 360.0, ofac = 5)\n",
    "\n",
    "def add_autoregAttr(cell):\n",
    "    \"\"\"\n",
    "    Computes autoregressive model-based periodogram and adds PdgramAttr\n",
    "    attributes\n",
    "    \"\"\"\n",
    "    cell.flavin.autoreg = pipeline.PdgramAttr()\n",
    "    cell.flavin.autoreg.label = \\\n",
    "            'Autogressive Model-Based Periodogram (Jia & Grima, 2020)'\n",
    "    cell.flavin.autoreg.power_label = 'Power'\n",
    "    freq_npoints = 1000\n",
    "    cell.flavin.autoreg.freqs, cell.flavin.autoreg.power = \\\n",
    "            pipeline.periodogram.autoreg(cell.time,\n",
    "                                         cell.flavin.reading_processed,\n",
    "                                         freq_npoints)\n",
    "\n",
    "# FLAVIN: import data and process objects\n",
    "\n",
    "# Import fluorescence info from CSVs\n",
    "Dset_flavin = pipeline.dataimport.import_timeseries(\n",
    "    filename_prefix+'flavin.csv', remain = 0.8)\n",
    "# dummy so I get code to not complain; will be re-factored later\n",
    "Dset_dcategory = [3] * len(Dset_flavin)\n",
    "Dset_births = pipeline.dataimport.import_births(\n",
    "    filename_prefix+'births.csv')\n",
    "\n",
    "# Arranges information into DatasetAttr objects\n",
    "Dset_data = pipeline.dataimport.CellAttr_from_datasets( \\\n",
    "        timeseries_df = Dset_flavin,\n",
    "        categories_array = Dset_dcategory,\n",
    "        births_df = Dset_births,\n",
    "        sampling_pd = sampling_period)\n",
    "Dset = pipeline.DatasetAttr(Dset_data)\n",
    "\n",
    "# Add labels\n",
    "strainlookup = pd.read_csv(filename_prefix+'strains.csv', \\\n",
    "                          index_col = 'position')\n",
    "for ii, cell in enumerate(Dset.cells):\n",
    "    cell.source = filename_prefix\n",
    "    cell.medium.base = 'Delft'\n",
    "    cell.medium.nutrients = {'glucose': 10}\n",
    "\n",
    "    cell.strain = strainlookup.loc[cell.position].strain\n",
    "\n",
    "    cell.flavin = pipeline.Fluo('flavin')\n",
    "    cell.flavin.exposure = 60\n",
    "    cell.flavin.reading = cell.y\n",
    "    cell.flavin.category = Dset_dcategory[ii]\n",
    "\n",
    "\n",
    "# mCherry: import data and process objects\n",
    "try:\n",
    "    Dset_mCherry_unsliced = pipeline.dataimport.import_timeseries(\n",
    "        filename_prefix+'mCherry.csv', remain = 0.8)\n",
    "    # restrict to cells with flavin readings\n",
    "    idx_both = list(set(Dset_flavin.cellID) & set(Dset_mCherry_unsliced.cellID))\n",
    "    Dset_mCherry = \\\n",
    "            Dset_mCherry_unsliced.loc[Dset_mCherry_unsliced.cellID.isin(idx_both)]\n",
    "\n",
    "    # Arranges information into DatasetAttr objects\n",
    "    # dummy -- will be better when I re-structure things... am just re-using a \n",
    "    # function for quick-and-dirty purposes, and it's obviously redundant\n",
    "    mCherry_data = pipeline.dataimport.CellAttr_from_datasets( \\\n",
    "            timeseries_df = Dset_mCherry,\n",
    "            categories_array = Dset_dcategory,\n",
    "            births_df = Dset_births,\n",
    "            sampling_pd = sampling_period)\n",
    "    mCherry = pipeline.DatasetAttr(mCherry_data)\n",
    "    mCherry_MATLABids = [cell.MATLABid for cell in mCherry.cells]\n",
    "\n",
    "    # Add labels\n",
    "    for ii, cell in enumerate(Dset.cells):\n",
    "        cell.mCherry = pipeline.Fluo('mCherry')\n",
    "        if cell.strain == 'htb2_mCherry_CRISPR':\n",
    "            cell.mCherry.exposure = 100\n",
    "        else:\n",
    "            cell.mCherry.exposure = 0\n",
    "\n",
    "        # loads in reading, cross-referencing by MATLABid.  This is awful, I know.\n",
    "        if cell.MATLABid in mCherry_MATLABids:\n",
    "            cell.mCherry.reading = \\\n",
    "                mCherry.cells[mCherry_MATLABids.index(cell.MATLABid)].y\n",
    "except FileNotFoundError as error:\n",
    "    print(error)\n",
    "    print(f'No mCherry time series associated with this experiment: {filename_prefix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define working dataset (list of cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wlist = Dset.cells\n",
    "#Wlist = [cell for cell in Dset.cells if cell.strain == 'FY4']\n",
    "len(Wlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in itertools.chain(Wlist):\n",
    "    cell.flavin.reading_processed = \\\n",
    "            pipeline.tsman.stdfilter(cell.flavin.reading, Fs = 1/sampling_period)\n",
    "pipeline.tsman.population_detrend(Wlist, 'flavin.reading_processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: chop up time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_start = 0\n",
    "interval_end = 168\n",
    "\n",
    "for cell in Wlist:\n",
    "    cell.time = cell.time[interval_start:interval_end]\n",
    "    cell.flavin.reading = cell.flavin.reading[interval_start:interval_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: normalise for heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in Wlist:\n",
    "    ts_mean = np.nanmean(cell.flavin.reading)\n",
    "    ts_range = np.nanmax(cell.flavin.reading) - np.nanmin(cell.flavin.reading)\n",
    "    cell.flavin.reading_processed = (cell.flavin.reading - ts_mean)/ts_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: add spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in Wlist:\n",
    "    cell.flavin.reading_processed = cell.flavin.reading\n",
    "    add_classicalAttr(cell, oversampling_factor = 1)\n",
    "    #add_bglsAttr(cell)\n",
    "    add_autoregAttr(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swe1_Del\n",
      "405\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "cell_index = 404\n",
    "y_attr = 'flavin.reading'\n",
    "\n",
    "Wlist[cell_index].plot_ts(y_attr=y_attr)\n",
    "print(Wlist[cell_index].strain)\n",
    "print(Wlist[cell_index].MATLABid)\n",
    "print(Wlist[cell_index].position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With CSHL2021/BYG2021 colour palette\n",
    "# (insert code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kymograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_attr = 'flavin.reading_processed'\n",
    "\n",
    "pipeline.vis.kymograph(Wlist, cell_attr=cell_attr,\n",
    "                      order_by='distfromcentre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchrony of YMCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_prefix = './data/arin/Omero19972_'\n",
    "# THEN RUN MAIN SHEBANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wlist = [cell for cell in Dset.cells if cell.strain == 'FY4']\n",
    "len(Wlist[0].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glucose: 0 - 83\n",
    "# Starvation: 84 - 180\n",
    "# Recovery: 181 - 264\n",
    "\n",
    "def kymograph_chopped(Wlist, interval_start, interval_end):\n",
    "    # Chops time series\n",
    "    for cell in Wlist:\n",
    "        cell.time = cell.time[interval_start:interval_end]\n",
    "        cell.flavin.reading = cell.flavin.reading[interval_start:interval_end]\n",
    "    # Normalise for kymograph\n",
    "    for cell in Wlist:\n",
    "        ts_mean = np.nanmean(cell.flavin.reading)\n",
    "        ts_range = np.nanmax(cell.flavin.reading) - np.nanmin(cell.flavin.reading)\n",
    "        cell.flavin.reading_processed = (cell.flavin.reading - ts_mean)/ts_range\n",
    "    # Draws kymograph\n",
    "    pipeline.vis.kymograph(Wlist, cell_attr='flavin.reading_processed',\n",
    "                          order_by='distfromcentre')\n",
    "\n",
    "kymograph_chopped(Wlist, 181, 264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-5c1c5d7812ad>:11: RuntimeWarning: invalid value encountered in log2\n",
      "  cell.flavin.reading_processed = np.log2(cell.flavin.reading / ts_mean)\n"
     ]
    }
   ],
   "source": [
    "# Spellman et al (1998)\n",
    "\n",
    "def kymograph_chopped(Wlist, interval_start, interval_end):\n",
    "    # Chops time series\n",
    "    for cell in Wlist:\n",
    "        cell.time = cell.time[interval_start:interval_end]\n",
    "        cell.flavin.reading = cell.flavin.reading[interval_start:interval_end]\n",
    "    # Normalise for kymograph\n",
    "    for cell in Wlist:\n",
    "        ts_mean = np.nanmean(cell.flavin.reading)\n",
    "        cell.flavin.reading_processed = np.log2(cell.flavin.reading / ts_mean)\n",
    "    # Draws kymograph\n",
    "    pipeline.vis.kymograph(Wlist, cell_attr='flavin.reading_processed',\n",
    "                          order_by='distfromcentre')\n",
    "\n",
    "kymograph_chopped(Wlist, 84, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.flavin.reading\n",
    "ts_mean = np.nanmean(cell.flavin.reading)\n",
    "cell.flavin.reading_processed = np.log2(cell.flavin.reading / ts_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(cell.flavin.reading)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(cell.flavin.reading_processed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causton strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_prefix = './data/arin/Omero19979_'\n",
    "# THEN RUN MAIN SHEBANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chops time series - i.e. before glucose limitation\n",
    "# WARNING: DO THIS ONCE\n",
    "interval_start = 0\n",
    "interval_end = 168\n",
    "for cell in Dset.cells:\n",
    "    cell.time = cell.time[interval_start:interval_end]\n",
    "    cell.flavin.reading = cell.flavin.reading[interval_start:interval_end]\n",
    "strain_list = ['swe1_Del', 'tsa1_Del_tsa2_Del', 'rim11_Del']\n",
    "for strain in strain_list:\n",
    "    # Choose cells corresponding to strain\n",
    "    Wlist = [cell for cell in Dset.cells if cell.strain == strain]\n",
    "    # Normalise for kymograph\n",
    "    for cell in Wlist:\n",
    "        ts_mean = np.nanmean(cell.flavin.reading)\n",
    "        ts_range = np.nanmax(cell.flavin.reading) - np.nanmin(cell.flavin.reading)\n",
    "        cell.flavin.reading_processed = (cell.flavin.reading - ts_mean)/ts_range\n",
    "    # Draws kymograph\n",
    "    pipeline.vis.kymograph(Wlist, cell_attr='flavin.reading_processed',\n",
    "                          order_by='distfromcentre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZWF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_prefix = './data/arin/Omero20016_'\n",
    "# THEN RUN MAIN SHEBANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chops time series - i.e. before glucose limitation\n",
    "# WARNING: DO THIS ONCE\n",
    "interval_start = 0\n",
    "interval_end = 168\n",
    "for cell in Dset.cells:\n",
    "    cell.time = cell.time[interval_start:interval_end]\n",
    "    cell.flavin.reading = cell.flavin.reading[interval_start:interval_end]\n",
    "strain_list = ['zwf1_Del', 'by4741']\n",
    "for strain in strain_list:\n",
    "    # Choose cells corresponding to strain\n",
    "    Wlist = [cell for cell in Dset.cells if cell.strain == strain]\n",
    "    # Normalise for kymograph\n",
    "    for cell in Wlist:\n",
    "        ts_mean = np.nanmean(cell.flavin.reading)\n",
    "        ts_range = np.nanmax(cell.flavin.reading) - np.nanmin(cell.flavin.reading)\n",
    "        cell.flavin.reading_processed = (cell.flavin.reading - ts_mean)/ts_range\n",
    "    # Draws kymograph\n",
    "    pipeline.vis.kymograph(Wlist, cell_attr='flavin.reading_processed',\n",
    "                          order_by='distfromcentre')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
