{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a6f437",
   "metadata": {},
   "source": [
    "**Purpose:** See how YMCs in mutants differ from each other and wild-type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c071c",
   "metadata": {},
   "source": [
    "**Aims:**\n",
    "- Import flavin signals from multiple strains in the same experiment (and thus same nutrient conditions).\n",
    "   - Obvious dataset: Causton strains, because there are five strains.\n",
    "- Process data: cut time series to duration of interest, detrend flavin signals.\n",
    "- Featurise data: use `catch22`\n",
    "- Use UMAP to visualise the relationship between the data.\n",
    "   - Adjust hyperparameters as appropriate to help with visualisation.\n",
    "   - Potentially use the labels themselves to perform supervised UMAP.  This will hopefully separate the classes while retaining some local and global structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b451b0",
   "metadata": {},
   "source": [
    "**Paradigms:**\n",
    "- Use `aliby` data structures, i.e. `pandas` `DataFrames` with multi-indexing.\n",
    "- Use `postprocessor` processes for featurisation\n",
    "- Use `scikit-learn` and `umap` routines.\n",
    "- Ultimate goal to put all the cells together in a script to put in `skeletons` (especially if `svm_sandbox.ipynb` and `cycle_alignment_sandbox.ipynb` share *many* cells with this one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6f33f",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ad1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# PARAMETERS\n",
    "filename_prefix = './data/arin/Omero19979_'\n",
    "#filename_prefix = './data/arin/Omero20016_'\n",
    "#\n",
    "\n",
    "# Import flavin signals\n",
    "signal_flavin = pd.read_csv(filename_prefix+'flavin.csv')\n",
    "signal_flavin.replace(0, np.nan, inplace=True) # because the CSV is constructed like that :/\n",
    "\n",
    "def convert_df_to_aliby(\n",
    "    signal,\n",
    "    strainlookup_df,\n",
    "):\n",
    "    # Import look-up table for strains (would prefer to directly CSV -> dict)\n",
    "    strainlookup_dict = dict(zip(strainlookup_df.position, strainlookup_df.strain))\n",
    "    \n",
    "    # Positions -> Strain (more informative)\n",
    "    signal = signal.replace({'position': strainlookup_dict})\n",
    "    signal.rename(columns = {\"position\": \"strain\"}, inplace = True)\n",
    "    signal = signal.drop(['distfromcentre'], axis = 1)\n",
    "\n",
    "    # Convert to multi-index dataframe\n",
    "    signal_temp = signal.iloc[:,2:]\n",
    "    multiindex = pd.MultiIndex.from_frame(signal[['strain', 'cellID']])\n",
    "    signal = pd.DataFrame(signal_temp.to_numpy(),\n",
    "                          index = multiindex)\n",
    "    \n",
    "    return signal\n",
    "\n",
    "strainlookup_df = pd.read_csv(filename_prefix+'strains.csv')\n",
    "signal_flavin = convert_df_to_aliby(signal_flavin, strainlookup_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8573754",
   "metadata": {},
   "source": [
    "# Processing time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a72d407",
   "metadata": {},
   "source": [
    "## Range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c736404a",
   "metadata": {},
   "source": [
    "Chop up time series according to `interval_start` and `interval_end`, then remove cells that have NaNs.  Print number of cells of each strain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c130febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "interval_start = 25\n",
    "interval_end = 168\n",
    "#\n",
    "\n",
    "signal_flavin_processed = signal_flavin.iloc[:, interval_start:interval_end].dropna()\n",
    "\n",
    "signal_flavin_processed.index.get_level_values(0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e4f62",
   "metadata": {},
   "source": [
    "## Detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921db7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PARAMETERS\n",
    "window = 45\n",
    "#\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(signal_flavin_processed)\n",
    "plt.title('Before detrending')\n",
    "plt.show()\n",
    "\n",
    "def moving_average(input_timeseries,\n",
    "                  window = 3):\n",
    "    processed_timeseries = np.cumsum(input_timeseries, dtype=float)\n",
    "    processed_timeseries[window:] = processed_timeseries[window:] - processed_timeseries[:-window]\n",
    "    return processed_timeseries[window - 1 :] /  window\n",
    "\n",
    "signal_flavin_processed = signal_flavin_processed.div(signal_flavin_processed.mean(axis = 1), axis = 0)\n",
    "signal_flavin_movavg = signal_flavin_processed.apply(lambda x: pd.Series(moving_average(x.values, window)), axis = 1)\n",
    "signal_flavin_norm = signal_flavin_processed.iloc(axis = 1)[window//2: -window//2] / signal_flavin_movavg.iloc[:,0:signal_flavin_movavg.shape[1]-1].values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(signal_flavin_norm)\n",
    "plt.title('After detrending')\n",
    "plt.show()\n",
    "\n",
    "signal_flavin_processed = signal_flavin_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c59aa",
   "metadata": {},
   "source": [
    "# Featurisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f58c29",
   "metadata": {},
   "source": [
    "Featurisation, using `catch22`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc58c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessor.core.processes.catch22 import catch22Parameters, catch22\n",
    "\n",
    "catch22_processor = catch22(catch22Parameters.default())\n",
    "features = catch22_processor.run(signal_flavin_processed)\n",
    "\n",
    "sns.heatmap(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f6ad7",
   "metadata": {},
   "source": [
    "Optionally, choose a subset of the `catch22` features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf12ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "osc_features_subset = [\n",
    "    'CO_Embed2_Dist_tau_d_expfit_meandiff',\n",
    "    'SP_Summaries_welch_rect_area_5_1',\n",
    "    'SB_MotifThree_quantile_hh',\n",
    "    'FC_LocalSimple_mean1_tauresrat',\n",
    "    #'CO_f1ecac',\n",
    "]\n",
    "strain_features_subset = [\n",
    "    'SP_Summaries_welch_rect_centroid',\n",
    "    'PD_PeriodicityWang_th0_01',\n",
    "    'FC_LocalSimple_mean3_stderr',\n",
    "    'CO_FirstMin_ac',\n",
    "    'CO_HistogramAMI_even_2_5',\n",
    "    \n",
    "]\n",
    "features = features[strain_features_subset]\n",
    "\n",
    "sns.heatmap(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03401d00",
   "metadata": {},
   "source": [
    "Alternatively, use time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d304e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = signal_flavin_processed\n",
    "\n",
    "sns.heatmap(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e2131",
   "metadata": {},
   "source": [
    "Normalise features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd845d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaled_features = StandardScaler().fit_transform(features)\n",
    "\n",
    "sns.heatmap(scaled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592f181",
   "metadata": {},
   "source": [
    "Scatterplot matrix of the first 10 features (there is probably space for `train.importance` around here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scaled_features[:, 2:5])\n",
    "df['strain'] = pd.Series(signal_flavin_processed.index.get_level_values(0))\n",
    "sns.pairplot(df, hue='strain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6abea7f",
   "metadata": {},
   "source": [
    "# Unsupervised methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0184151",
   "metadata": {},
   "source": [
    "Label by strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_labels = signal_flavin_processed.index.get_level_values('strain')\n",
    "strain_unique = strain_labels.unique().to_list()\n",
    "strain_map = dict(zip(strain_unique, list(range(len(strain_unique)))))\n",
    "strain_labels_numerical = [strain_map.get(item, item) for item in strain_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841b0b2",
   "metadata": {},
   "source": [
    "Load custom labels (e.g. oscillation categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9f9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "filename_targets = 'categories_19979_detrend.csv'\n",
    "#\n",
    "\n",
    "targets = pd.read_csv(filename_targets, header = None, index_col = 0)\n",
    "targets.index.names = ['cellID']\n",
    "targets.columns = ['category']\n",
    "\n",
    "customcat_labels = np.array([\n",
    "    targets.loc[cellID].item()\n",
    "    for cellID in signal_flavin_processed.index.get_level_values('cellID')\n",
    "])\n",
    "customcat_labels_numerical = customcat_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1bf064",
   "metadata": {},
   "source": [
    "Combine strain and oscillation categories to produce colour keys:\n",
    "- If there are n strains, those strains will have numerical labels of 1 to n and will correspond to n colours of the palette.\n",
    "- Non-oscillating nodes from _any_ strain will have a numerical label of 0 and will correspond to grey.\n",
    "- Defining it this way because `matplotlib` conveniently has a couple of qualitative colour maps that has grey as the last colour.  I reverse it so that grey is the first; intuitively it's easier to work with if 0 consistently corresponds to grey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb53d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "\n",
    "# Strain names or 'non-oscillatory'\n",
    "combined_labels = [\n",
    "    strain_labels[index] if customcat_labels[index] == 1 else 'non-oscillatory'\n",
    "    for index, _ in enumerate(customcat_labels)\n",
    "]\n",
    "# Numbers, as described above\n",
    "combined_labels_numerical = [\n",
    "    strain_labels_numerical[index]+1 if customcat_labels_numerical[index] == 1 else 0\n",
    "    for index, _ in enumerate(customcat_labels_numerical)\n",
    "]\n",
    "# Create a palette out of cm\n",
    "palette_cm = cm.get_cmap('Set1_r', len(strain_unique)+1)\n",
    "combined_labels_numerical_unique = np.unique(combined_labels_numerical)\n",
    "palette_rgb = [\n",
    "    colors.rgb2hex(palette_cm(index/len(combined_labels_numerical_unique))[:3])\n",
    "    for index, _ in enumerate(combined_labels_numerical_unique)\n",
    "]\n",
    "# Dict to map label to colour\n",
    "palette_map = dict(zip(\n",
    "    np.concatenate((['non-oscillatory'], strain_unique)).tolist(),\n",
    "    palette_rgb\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719f0ca",
   "metadata": {},
   "source": [
    "Optional: make non-oscillatory white and transparent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f882d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_map['non-oscillatory'] = '#ffffff00'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff96a70",
   "metadata": {},
   "source": [
    "Optional: delete non-oscillatory time series from the (scaled) feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "\n",
    "osc_mask = np.array([label != 'non-oscillatory' for label in combined_labels])\n",
    "scaled_features = scaled_features[osc_mask]\n",
    "combined_labels = list(compress(combined_labels, osc_mask.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818dd448",
   "metadata": {},
   "source": [
    "## Pairwise cosine distance for feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e95d4",
   "metadata": {},
   "source": [
    "This checks whether there are meaningful distances between sets of data.  If there are no such distances, then the UMAP will perform badly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sklearn\n",
    "\n",
    "# Optional: exclude non-oscillatory\n",
    "excl_non_osc = True\n",
    "\n",
    "label_list = np.unique(combined_labels)\n",
    "if excl_non_osc:\n",
    "    non_osc_index = np.where(label_list == 'non-oscillatory')[0]\n",
    "    if non_osc_index.size > 0:\n",
    "        label_list = np.delete(label_list, non_osc_index)\n",
    "\n",
    "for label1, label2 in itertools.combinations(label_list, 2):\n",
    "    # Subset and compute the pairwise cosine distances\n",
    "    label1_mask = np.array([True if label == label1 else False for label in combined_labels])\n",
    "    label2_mask = np.array([True if label == label2 else False for label in combined_labels])\n",
    "    cosine_distance_matrix = sklearn.metrics.pairwise.cosine_distances(\n",
    "        scaled_features[label1_mask,:],\n",
    "        scaled_features[label2_mask,:]\n",
    "    )\n",
    "    # Plot hierarchically-clustered heatmaps\n",
    "    #fig, ax = plt.subplots()\n",
    "    ax = sns.clustermap(\n",
    "        cosine_distance_matrix,\n",
    "        cmap = 'mako_r',\n",
    "        vmin = 0,\n",
    "        vmax = 2,\n",
    "    )\n",
    "    plt.title(label1 + ' vs ' + label2 + ': mean' + str(np.mean(cosine_distance_matrix)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414e8c0f",
   "metadata": {},
   "source": [
    "## PCA-instantiated UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcecdd7",
   "metadata": {},
   "source": [
    "This checks whether there are correlations between features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf0884",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_save = scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = scaled_features_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Define dimensions\n",
    "n_components = 2\n",
    "\n",
    "# Fit\n",
    "reducer = PCA(\n",
    "    n_components = n_components,\n",
    ")\n",
    "\n",
    "mapper = reducer.fit(\n",
    "    scaled_features,\n",
    ").transform(scaled_features)\n",
    "\n",
    "# Plot\n",
    "if n_components == 2:\n",
    "    # Plotting may not be desired if n_components > 2\n",
    "    sns.scatterplot(\n",
    "        x = mapper[:,0],\n",
    "        y = mapper[:,1],\n",
    "        hue = combined_labels,\n",
    "        palette = palette_map,\n",
    "        s = 10,\n",
    "    )\n",
    "    plt.title(\n",
    "        'Experiment '+'20016'+', '\n",
    "        +'featurisation using '+'PCA'+', '\n",
    "        +'labelling '+'strains'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d10455",
   "metadata": {},
   "source": [
    "Redefine `scaled_features` so that I can just abuse the UMAP cells below.  The PCA embeddings are now my new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d6c1f",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9cd43",
   "metadata": {},
   "source": [
    "Fit and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import umap.plot\n",
    "\n",
    "# Fit\n",
    "reducer = umap.UMAP(\n",
    "    random_state = 42,\n",
    "    n_neighbors = 20,\n",
    "    min_dist = 0.5,\n",
    "    n_components = 2,\n",
    "    #metric = 'cosine',\n",
    ")\n",
    "mapper = reducer.fit(scaled_features)\n",
    "\n",
    "# Plot\n",
    "umap.plot.points(\n",
    "    mapper,\n",
    "    labels = np.array(combined_labels),\n",
    "    color_key = palette_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a667a4",
   "metadata": {},
   "source": [
    "To do: add way to mouse over points and see what the time series looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d4a116",
   "metadata": {},
   "source": [
    "Vary hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import umap\n",
    "import umap.plot\n",
    "\n",
    "# Wrap UMAP fitting and plotting into one function,\n",
    "# taking matplotlib axis as an argument\n",
    "def generate_umap(\n",
    "    scaled_features,\n",
    "    n_neighbors,\n",
    "    min_dist,\n",
    "    combined_labels,\n",
    "    palette_map,\n",
    "    ax = None,\n",
    "):\n",
    "    reducer = umap.UMAP(\n",
    "        random_state = 42,\n",
    "        n_neighbors = n_neighbors,\n",
    "        min_dist = min_dist,\n",
    "        n_components = 2,\n",
    "        #metric = 'cosine',\n",
    "    )\n",
    "    mapper = reducer.fit(scaled_features)\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax = umap.plot.points(\n",
    "        mapper,\n",
    "        labels = np.array(combined_labels),\n",
    "        color_key = palette_map,\n",
    "        show_legend = False,\n",
    "        ax = ax,\n",
    "    )\n",
    "    return ax\n",
    "\n",
    "# Define values of hyperparameters to iterate over here:\n",
    "hyperparams_to_iterate = {\n",
    "    'n_neighbors' : [5, 10, 20, 50, 100, 150],\n",
    "    'min_dist' : [0.00, 0.25, 0.50, 1],\n",
    "}\n",
    "\n",
    "# Plot UMAPs in a grid\n",
    "fig, axs = plt.subplots(\n",
    "    len(hyperparams_to_iterate['n_neighbors']),\n",
    "    len(hyperparams_to_iterate['min_dist'])\n",
    ")\n",
    "#fig.tight_layout(pad = 0.5)\n",
    "for n_neighbors_index, n_neighbors in enumerate(hyperparams_to_iterate['n_neighbors']):\n",
    "    for min_dist_index, min_dist in enumerate(hyperparams_to_iterate['min_dist']):\n",
    "        axs[n_neighbors_index, min_dist_index] = generate_umap(\n",
    "            scaled_features,\n",
    "            n_neighbors,\n",
    "            min_dist,\n",
    "            combined_labels,\n",
    "            palette_map,\n",
    "            ax = axs[n_neighbors_index, min_dist_index],\n",
    "        )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aliby",
   "language": "python",
   "name": "aliby"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
