{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75330d2c",
   "metadata": {},
   "source": [
    "Aims:\n",
    "- Do AR to fit model to time series and get features.  Trying frequency of oscillations for now, potential to expand to quality (height of peak of periodogram).\n",
    "- Do it with Causton strains.  With potential to switch to the experiment with the new CEN.PK if I have time.\n",
    "- Produce some plots for BYG201 (panel 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ea35c",
   "metadata": {},
   "source": [
    "Specify file name and sampling period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adab97ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "#filename_prefix = './data/arin/Omero19979_'\n",
    "filename_prefix = './data/arin/Omero20016_'\n",
    "sampling_period = 5\n",
    "remain = 0.8\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a68cc8a",
   "metadata": {},
   "source": [
    "Main shebang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4deb26db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './data/arin/Omero20016_mCherry.csv'\n",
      "No mCherry time series associated with this experiment: ./data/arin/Omero20016_\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "import igraph as ig\n",
    "\n",
    "import pipeline.dataexport\n",
    "import pipeline.dataimport\n",
    "import pipeline.periodogram\n",
    "import pipeline.score\n",
    "import pipeline.tsman\n",
    "import pipeline.vis\n",
    "\n",
    "import featext.tsman\n",
    "import featext.graph\n",
    "#import featext.vis\n",
    "\n",
    "#import catch22\n",
    "#import leidenalg\n",
    "\n",
    "def add_classicalAttr(cell, oversampling_factor = 1):\n",
    "    \"\"\"Computes classical periodogram and adds PdgramAttr attributes\"\"\"\n",
    "    cell.flavin.classical.freqs, cell.flavin.classical.power = \\\n",
    "            pipeline.periodogram.classical(cell.time, cell.flavin.reading_processed,\n",
    "                                oversampling_factor = oversampling_factor)\n",
    "\n",
    "def add_bglsAttr(cell):\n",
    "    \"\"\"Computes BGLS and adds PdgramAttr attributes\"\"\"\n",
    "    cell.flavin.bgls = pipeline.PdgramAttr()\n",
    "    cell.flavin.bgls.label = 'Bayesian General Lomb-Scargle Periodogram'\n",
    "    cell.flavin.bgls.power_label = 'Probability'\n",
    "    err = np.ones(len(cell.flavin.reading_processed))*\\\n",
    "            np.sqrt(np.max(cell.flavin.reading_processed))\n",
    "    cell.flavin.bgls.freqs, cell.flavin.bgls.power = \\\n",
    "            pipeline.periodogram.bgls(cell.time, cell.flavin.reading_processed, err,\n",
    "                    plow = 30.0, phigh = 360.0, ofac = 5)\n",
    "\n",
    "def add_autoregAttr(cell):\n",
    "    \"\"\"\n",
    "    Computes autoregressive model-based periodogram and adds PdgramAttr\n",
    "    attributes\n",
    "    \"\"\"\n",
    "    cell.flavin.autoreg = pipeline.PdgramAttr()\n",
    "    cell.flavin.autoreg.label = \\\n",
    "            'Autogressive Model-Based Periodogram (Jia & Grima, 2020)'\n",
    "    cell.flavin.autoreg.power_label = 'Power'\n",
    "    freq_npoints = 1000\n",
    "    cell.flavin.autoreg.order, cell.flavin.autoreg.freqs, cell.flavin.autoreg.power = \\\n",
    "            pipeline.periodogram.autoreg(cell.time,\n",
    "                                         cell.flavin.reading_processed,\n",
    "                                         freq_npoints)\n",
    "\n",
    "# FLAVIN: import data and process objects\n",
    "\n",
    "# Import fluorescence info from CSVs\n",
    "Dset_flavin = pipeline.dataimport.import_timeseries(\n",
    "    filename_prefix+'flavin.csv', remain = remain)\n",
    "# dummy so I get code to not complain; will be re-factored later\n",
    "Dset_dcategory = [3] * len(Dset_flavin)\n",
    "Dset_births = pipeline.dataimport.import_births(\n",
    "    filename_prefix+'births.csv')\n",
    "\n",
    "# Arranges information into DatasetAttr objects\n",
    "Dset_data = pipeline.dataimport.CellAttr_from_datasets( \\\n",
    "        timeseries_df = Dset_flavin,\n",
    "        categories_array = Dset_dcategory,\n",
    "        births_df = Dset_births,\n",
    "        sampling_pd = sampling_period)\n",
    "Dset = pipeline.DatasetAttr(Dset_data)\n",
    "\n",
    "# Add labels\n",
    "strainlookup = pd.read_csv(filename_prefix+'strains.csv', \\\n",
    "                          index_col = 'position')\n",
    "for ii, cell in enumerate(Dset.cells):\n",
    "    cell.source = filename_prefix\n",
    "    cell.medium.base = 'Delft'\n",
    "    cell.medium.nutrients = {'glucose': 10}\n",
    "\n",
    "    cell.strain = strainlookup.loc[cell.position].strain\n",
    "\n",
    "    cell.flavin = pipeline.Fluo('flavin')\n",
    "    cell.flavin.exposure = 60\n",
    "    cell.flavin.reading = cell.y\n",
    "    cell.flavin.category = Dset_dcategory[ii]\n",
    "\n",
    "\n",
    "# mCherry: import data and process objects\n",
    "try:\n",
    "    Dset_mCherry_unsliced = pipeline.dataimport.import_timeseries(\n",
    "        filename_prefix+'mCherry.csv', remain = remain)\n",
    "    # restrict to cells with flavin readings\n",
    "    idx_both = list(set(Dset_flavin.cellID) & set(Dset_mCherry_unsliced.cellID))\n",
    "    Dset_mCherry = \\\n",
    "            Dset_mCherry_unsliced.loc[Dset_mCherry_unsliced.cellID.isin(idx_both)]\n",
    "\n",
    "    # Arranges information into DatasetAttr objects\n",
    "    # dummy -- will be better when I re-structure things... am just re-using a \n",
    "    # function for quick-and-dirty purposes, and it's obviously redundant\n",
    "    mCherry_data = pipeline.dataimport.CellAttr_from_datasets( \\\n",
    "            timeseries_df = Dset_mCherry,\n",
    "            categories_array = Dset_dcategory,\n",
    "            births_df = Dset_births,\n",
    "            sampling_pd = sampling_period)\n",
    "    mCherry = pipeline.DatasetAttr(mCherry_data)\n",
    "    mCherry_MATLABids = [cell.MATLABid for cell in mCherry.cells]\n",
    "\n",
    "    # Add labels\n",
    "    for ii, cell in enumerate(Dset.cells):\n",
    "        cell.mCherry = pipeline.Fluo('mCherry')\n",
    "        if cell.strain == 'htb2_mCherry_CRISPR':\n",
    "            cell.mCherry.exposure = 100\n",
    "        else:\n",
    "            cell.mCherry.exposure = 0\n",
    "\n",
    "        # loads in reading, cross-referencing by MATLABid.  This is awful, I know.\n",
    "        if cell.MATLABid in mCherry_MATLABids:\n",
    "            cell.mCherry.reading = \\\n",
    "                mCherry.cells[mCherry_MATLABids.index(cell.MATLABid)].y\n",
    "except FileNotFoundError as error:\n",
    "    print(error)\n",
    "    print(f'No mCherry time series associated with this experiment: {filename_prefix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a69ca0d",
   "metadata": {},
   "source": [
    "Define working dataset (list of cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd83262e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1330"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wlist = Dset.cells\n",
    "#Wlist = [cell for cell in Dset.cells if cell.strain == 'swe1_Del']\n",
    "len(Wlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd07a0",
   "metadata": {},
   "source": [
    "Chop up time series (exclude the end in which there is starvation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33be433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_start = 0\n",
    "interval_end = 168\n",
    "\n",
    "for cell in Wlist:\n",
    "    cell.time = cell.time[interval_start:interval_end]\n",
    "    cell.flavin.reading = cell.flavin.reading[interval_start:interval_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0608bc",
   "metadata": {},
   "source": [
    "Remove cells than have NaNs.  AR doesn't like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44f19be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wlist = [cell for cell in Wlist if not np.isnan(cell.flavin.reading).any()]\n",
    "len(Wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d193ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'zwf1_Del': 446, 'by4741': 222})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count_strain = Counter([cell.strain for cell in Wlist])\n",
    "print(count_strain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5665d8",
   "metadata": {},
   "source": [
    "Sandbox: local regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8c0811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = Wlist[502].flavin.reading\n",
    "plt.plot(timeseries)\n",
    "plt.show()\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "timeseries_sg = savgol_filter(timeseries, window_length=15, polyorder=5)\n",
    "plt.plot(timeseries_sg)\n",
    "plt.show()\n",
    "\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "# Set period and seasonal according to the pd found by AR.  This could be a first approximation.\n",
    "# Otherwise, set it at 15 (75 min, a knowledge-informed first approximation)\n",
    "# But there's going to be an issue if I switch to a slower one e.g. zwf1...\n",
    "# Another approach is setting it at a low value, e.g. 7 and apply the same value to all time series.\n",
    "stl = STL(timeseries, period=25, seasonal=25, robust=False)\n",
    "res = stl.fit()\n",
    "fig = res.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5836f76",
   "metadata": {},
   "source": [
    "Add spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f38b77a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in Wlist:\n",
    "    cell.flavin.reading_processed = cell.flavin.reading\n",
    "    #add_classicalAttr(cell, oversampling_factor = 1)\n",
    "    add_autoregAttr(cell)\n",
    "    #print(cell.cellid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d035a8f",
   "metadata": {},
   "source": [
    "AR orders in whole dataset, by strain -- represented as histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "879e585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_positions = [list_position\n",
    "                  for (list_position, cell) in enumerate(Wlist)]\n",
    "\n",
    "ar_orders = pd.DataFrame(data = {\n",
    "    'list_position': list_positions,\n",
    "    'strain': [Wlist[list_position].strain for list_position in list_positions],\n",
    "    'order': [Wlist[list_position].flavin.autoreg.order for list_position in list_positions],\n",
    "})\n",
    "\n",
    "strain_list = set(ar_orders.strain)\n",
    "\n",
    "for strain in strain_list:\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.hist(\n",
    "        ar_orders.loc[ar_orders.strain == strain].order,\n",
    "        bins = np.arange(22))\n",
    "    plt.xticks(np.arange(22))\n",
    "    plt.title(strain)\n",
    "    plt.xlabel('order')\n",
    "    plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a04d90",
   "metadata": {},
   "source": [
    "Compute period of 'smoothed periodogram', if appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "171037e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arin/git/time-series-pipeline/pipeline/__init__.py:60: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.pd = (1/self.freqs[self.power == max(self.power)])[0]\n"
     ]
    }
   ],
   "source": [
    "for cell in Wlist:\n",
    "    cell.flavin.autoreg.add_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbafad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    list_position    strain       period  max_power  order\n",
      "0              60    by4741   324.350649   1.033094      5\n",
      "1              84    by4741    76.259542   1.291732     17\n",
      "2              88    by4741   396.428571   2.760693     18\n",
      "3             113    by4741   846.610169   1.243889     19\n",
      "4             118    by4741   423.305085   3.384517     19\n",
      "5             129    by4741  1611.290323   1.025469     17\n",
      "6             168    by4741   205.555556   1.633464     11\n",
      "7             185    by4741   832.500000   1.126909     16\n",
      "8             210    by4741   117.806604   1.895472      5\n",
      "9             248  zwf1_Del   177.127660   1.342261     12\n",
      "10            253  zwf1_Del   132.142857   7.870039      9\n",
      "11            254  zwf1_Del  1427.142857   1.000146      7\n",
      "12            263  zwf1_Del   306.441718   1.039466      5\n",
      "13            265  zwf1_Del   247.277228   1.061638      5\n",
      "14            268  zwf1_Del   129.069767   3.444091      7\n",
      "15            270  zwf1_Del   225.000000   4.965026     17\n",
      "16            285  zwf1_Del   354.255319   1.060761      7\n",
      "17            304  zwf1_Del   212.553191   3.088824      9\n",
      "18            322  zwf1_Del   236.729858   1.161699      7\n",
      "19            338  zwf1_Del   520.312500   1.030496      9\n",
      "20            344  zwf1_Del   182.967033   6.414453     15\n",
      "21            348  zwf1_Del   264.285714   1.130179      9\n",
      "22            351  zwf1_Del   393.307087   1.064408      7\n",
      "23            355  zwf1_Del   163.235294   2.478407      7\n",
      "24            362  zwf1_Del  1427.142857   1.000115      5\n",
      "25            363  zwf1_Del   229.128440   1.168446      7\n",
      "26            364  zwf1_Del   356.785714   1.300388     11\n",
      "27            387  zwf1_Del   256.153846   1.094352      5\n",
      "28            391  zwf1_Del   458.256881   1.039148      7\n",
      "29            408  zwf1_Del   567.613636   1.346771     19\n",
      "30            420  zwf1_Del   133.200000   1.118850      5\n",
      "31            450  zwf1_Del   203.877551   1.349982      6\n",
      "32            455  zwf1_Del   169.897959   2.296327      7\n",
      "33            482  zwf1_Del   387.209302   1.009752      4\n",
      "34            502  zwf1_Del   344.482759   1.045518      5\n",
      "35            511  zwf1_Del   475.714286   1.010496      5\n",
      "36            535  zwf1_Del   458.256881   1.013498      5\n",
      "37            538  zwf1_Del   155.124224   1.294695      5\n",
      "38            540  zwf1_Del   426.923077   1.009235      5\n",
      "39            569  zwf1_Del   213.461538   1.317849      5\n",
      "40            577  zwf1_Del   555.000000   1.009966      7\n",
      "41            585  zwf1_Del   375.563910   1.319428     11\n",
      "42            589  zwf1_Del   328.618421   1.664935     13\n",
      "43            590  zwf1_Del   337.500000   1.021049      7\n",
      "44            595  zwf1_Del   190.648855   2.492808      7\n",
      "45            596  zwf1_Del   370.000000   1.117464      7\n",
      "46            604  zwf1_Del  1513.636364   1.000299      7\n",
      "47            613  zwf1_Del   202.226721   2.558597      7\n",
      "48            622  zwf1_Del   287.068966   1.191494      9\n",
      "49            634  zwf1_Del   193.604651   1.078753      5\n",
      "50            640  zwf1_Del   218.122271   1.467210      7\n",
      "51            641  zwf1_Del   277.500000   1.075421      6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_positions = [list_position\n",
    "                  for (list_position, cell) in enumerate(Wlist)\n",
    "                  if np.isfinite(cell.flavin.autoreg.pd)]\n",
    "\n",
    "oscillating_cells = pd.DataFrame(data = {\n",
    "    'list_position': list_positions,\n",
    "    'strain': [Wlist[list_position].strain for list_position in list_positions],\n",
    "    'period': [Wlist[list_position].flavin.autoreg.pd for list_position in list_positions],\n",
    "    'max_power': [max(Wlist[list_position].flavin.autoreg.power) for list_position in list_positions],\n",
    "    'order': [Wlist[list_position].flavin.autoreg.order for list_position in list_positions],\n",
    "})\n",
    "\n",
    "print(oscillating_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05f58b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0029029]\n",
      "[344.48275862]\n"
     ]
    }
   ],
   "source": [
    "list_position = 502\n",
    "\n",
    "Wlist[list_position].plot_ts()\n",
    "Wlist[list_position].flavin.plot_ps(pdgram='autoreg', pd=False)\n",
    "from scipy.signal import find_peaks\n",
    "peaks, _ = find_peaks(Wlist[list_position].flavin.autoreg.power)\n",
    "print(Wlist[list_position].flavin.autoreg.freqs[peaks])\n",
    "print(1/np.array(Wlist[list_position].flavin.autoreg.freqs[peaks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59919710",
   "metadata": {},
   "source": [
    "White noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c66b1a8",
   "metadata": {},
   "source": [
    "Plotting one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a87230f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "timeaxis = Wlist[0].time\n",
    "timeseries = np.random.normal(0, 1, len(timeaxis))\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from pipeline.ar_grima2020 import AR_Fit, AR_Power, optimise_ar_order\n",
    "\n",
    "# Model TS\n",
    "optimal_ar_order = optimise_ar_order(timeseries, int(3*np.sqrt(len(timeseries))))\n",
    "print(optimal_ar_order)\n",
    "model = AR_Fit(timeseries, optimal_ar_order)\n",
    "timeseries_modelled = np.empty(model.length)\n",
    "for index in range(model.length):\n",
    "    if index < optimal_ar_order:\n",
    "        timeseries_modelled[index] = timeseries[index]\n",
    "    else:\n",
    "        preceding_points = timeseries[index-optimal_ar_order:index]\n",
    "        linear_combination = np.dot(model.ar_coeffs[1::], preceding_points[::-1])\n",
    "        timeseries_modelled[index] = linear_combination\n",
    "        \n",
    "# Plot time series\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10,4))\n",
    "ax.plot(timeaxis, timeseries, '#b785d5', label = 'White noise')\n",
    "ax.plot(timeaxis, timeseries_modelled, '#430467', label = 'Autoregressive model')\n",
    "ax.set_xlim([0,840])\n",
    "ax.set_xticks(np.linspace(0,800,9))\n",
    "ax.legend()\n",
    "plt.xlabel('Time (min)')\n",
    "plt.ylabel('Fluorescence, zero-centred (AU)')\n",
    "\n",
    "# Plot periodogram\n",
    "freq_npoints = 1000\n",
    "order, freqs, power = pipeline.periodogram.autoreg(timeaxis, timeseries, freq_npoints)\n",
    "peak_indices, _ = find_peaks(power)\n",
    "peak_locs = freqs[peak_indices]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, power, '#430467')\n",
    "for peak_index in peak_indices:\n",
    "    ax.axvline(freqs[peak_index], ymin = 0, ymax = power[peak_index],\n",
    "               color = '#6f0aaa', linestyle = ':')\n",
    "#ax.set_xlim([0,0.02])\n",
    "ax.set_xticks(np.linspace(0,0.02,5))\n",
    "#ax.set_ylim([0,14])\n",
    "ax.set_xlabel('Frequency ($min^{-1}$)')\n",
    "ax.set_ylabel('Power (dimensionless)')\n",
    "ax.set_title('Autoregressive Model-Based Periodogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66d025",
   "metadata": {},
   "source": [
    "Hacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a9c89c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0     7218\n",
      "2.0     1114\n",
      "3.0      528\n",
      "4.0      365\n",
      "5.0      246\n",
      "6.0      147\n",
      "7.0      122\n",
      "8.0       66\n",
      "9.0       64\n",
      "10.0      35\n",
      "11.0      30\n",
      "12.0      17\n",
      "13.0      15\n",
      "14.0      10\n",
      "15.0       9\n",
      "16.0       1\n",
      "17.0       7\n",
      "19.0       3\n",
      "20.0       1\n",
      "23.0       1\n",
      "26.0       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pipeline.ar_grima2020 import AR_Fit, AR_Power, optimise_ar_order\n",
    "\n",
    "iterations = 10000\n",
    "\n",
    "timeaxis = Wlist[0].time\n",
    "orders = np.empty(iterations)\n",
    "for iteration in range(iterations):\n",
    "    timeseries = np.random.normal(0, 1, len(timeaxis))\n",
    "    optimal_ar_order = optimise_ar_order(timeseries, int(3*np.sqrt(len(timeseries))))\n",
    "    orders[iteration] = optimal_ar_order\n",
    "    \n",
    "freq_table = pd.Series(orders).value_counts().sort_index()\n",
    "print(freq_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "579e872d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'white noise (n = 10,000)')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(orders, bins = np.arange(22))\n",
    "plt.xlabel('order')\n",
    "plt.ylabel('count')\n",
    "plt.title('white noise (n = 10,000)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437545b1",
   "metadata": {},
   "source": [
    "PROBLEM: there's only one swe1Δ cell that the AR identifies as oscillating.  Changes definitely need to be made to the algorithm.  Perhaps this is where the model selection comes in, but there's _no way_ I'll be able to explore this in time for the conference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7357e",
   "metadata": {},
   "source": [
    "# For poster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a744b",
   "metadata": {},
   "source": [
    "Causton - tsa1 tsa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "288a75cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41.75      ,   82.85      ,  152.83333333,  202.85      ,\n",
       "        247.88333333,  337.88333333,  347.86666667,  422.88333333,\n",
       "        492.86666667,  502.85      ,  577.88333333,  592.9       ,\n",
       "        652.88333333,  707.9       ,  737.91666667,  812.93333333,\n",
       "        857.88333333,  892.93333333, 1017.93333333])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wlist[264].births"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6cd2fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Fluorescence, zero-centred (AU)')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipeline.ar_grima2020 import AR_Fit, AR_Power, optimise_ar_order\n",
    "\n",
    "# Inputs\n",
    "births = np.array([41.75, 82.85, 152.83, 202.85, 247.88, 347.87, 422.88, 502.85, 577.88, 652.88, 707.9, 737.92, 812.93])\n",
    "timeaxis = Wlist[264].time\n",
    "timeseries = Wlist[264].flavin.reading - np.mean(Wlist[264].flavin.reading)\n",
    "\n",
    "# Model TS\n",
    "optimal_ar_order = optimise_ar_order(timeseries, int(3*np.sqrt(len(timeseries))))\n",
    "print(optimal_ar_order)\n",
    "model = AR_Fit(timeseries, optimal_ar_order)\n",
    "timeseries_modelled = np.empty(model.length)\n",
    "for index in range(model.length):\n",
    "    if index < optimal_ar_order:\n",
    "        timeseries_modelled[index] = timeseries[index]\n",
    "    else:\n",
    "        preceding_points = timeseries[index-optimal_ar_order:index]\n",
    "        linear_combination = np.dot(model.ar_coeffs[1::], preceding_points[::-1])\n",
    "        timeseries_modelled[index] = linear_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d771cb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Fluorescence, zero-centred (AU)')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot time series\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10,4))\n",
    "ax.plot(timeaxis, timeseries, '#b785d5', label = 'Biological time series')\n",
    "ax.plot(timeaxis, timeseries_modelled, '#430467', label = 'Autoregressive model')\n",
    "for birth_count, birth in enumerate(births):\n",
    "    if birth_count == 0:\n",
    "        ax.axvline(birth, ymin = 0, ymax = 1, color = '#6f0aaa', linestyle = '--', label = 'Birth event')\n",
    "    else:\n",
    "        ax.axvline(birth, ymin = 0, ymax = 1, color = '#6f0aaa', linestyle = '--')\n",
    "ax.set_xlim([0,840])\n",
    "ax.set_xticks(np.linspace(0,800,9))\n",
    "ax.legend()\n",
    "plt.title('Autoregressive model overlaid on biological time series')\n",
    "plt.title('tsa1Δ tsa2Δ')\n",
    "plt.xlabel('Time (min)')\n",
    "plt.ylabel('Fluorescence, zero-centred (AU)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f514147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot periodogram\n",
    "freqs = Wlist[264].flavin.autoreg.freqs\n",
    "power = Wlist[264].flavin.autoreg.power\n",
    "peak_indices, _ = find_peaks(Wlist[264].flavin.autoreg.power)\n",
    "peak_locs = freqs[peak_indices]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, power, '#430467')\n",
    "for peak_index in peak_indices:\n",
    "    ax.axvline(freqs[peak_index], ymin = 0, ymax = power[peak_index],\n",
    "               color = '#6f0aaa', linestyle = ':')\n",
    "ax.set_xlim([0,0.02])\n",
    "ax.set_xticks(np.linspace(0,0.02,5))\n",
    "#ax.set_ylim([0,14])\n",
    "ax.set_xlabel('Frequency ($min^{-1}$)')\n",
    "ax.set_ylabel('Power (dimensionless)')\n",
    "ax.set_title('Autoregressive Model-Based Periodogram')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
